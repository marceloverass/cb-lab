# Desafio Engenharia de Dados

## Resolu√ß√£o dos Desafios

Para facilitar a avalia√ß√£o, as solu√ß√µes para cada um dos desafios foram documentadas em Jupyter Notebooks separados. Cada notebook cont√©m a an√°lise detalhada e as respostas para as quest√µes propostas.

* **[üìÑ Notebook da Solu√ß√£o do Desafio 1](https://github.com/marceloverass/cb-lab/blob/main/docs/notebooks/desafio1.ipynb)**
* **[üìÑ Notebook da Solu√ß√£o do Desafio 2](https://github.com/marceloverass/cb-lab/blob/main/docs/notebooks/desafio2.ipynb)**

Para dar visibilidade ao processo de desenvolvimento, todo o gerenciamento do projeto foi organizado em um quadro Kanban, que detalha o fluxo de trabalho, o controle de tarefas e o progresso desde a concep√ß√£o at√© a entrega final.

* **[Kanban](https://github.com/marceloverass/cb-lab/blob/main/docs/KANBAN.md)**

## Descri√ß√£o

Este projeto implementa um pipeline de dados completo que ingere dados de uma fonte externa (API), processa-os atrav√©s de m√∫ltiplas camadas (Bronze, Silver e Gold) e os armazena em um Data Warehouse no SQL Server. Todo o ambiente, incluindo a aplica√ß√£o Python e o banco de dados, √© orquestrado com Docker.

O objetivo √© demonstrar habilidades em engenharia de dados, modelagem e arquitetura de dados, ETL, automa√ß√£o de processos e organiza√ß√£o de um ambiente de desenvolvimento reproduz√≠vel.

## Tecnologias Utilizadas

* **Linguagem:** Python 3.10
* **Banco de Dados:** Microsoft SQL Server
* **Conteineriza√ß√£o:** Docker & Docker Compose
* **Bibliotecas Principais:**
    * Pandas
    * SQLAlchemy
    * PyODBC

## Pr√©-requisitos

Antes de come√ßar, garanta que voc√™ tenha as seguintes ferramentas instaladas em sua m√°quina:

* [Git](https://git-scm.com/)
* [Docker](https://www.docker.com/products/docker-desktop/)
* [Docker Compose](https://docs.docker.com/compose/install/)

## Como Executar o Projeto

Siga os passos abaixo na ordem correta. Cada comando foi preparado para ser copiado e colado diretamente no seu terminal.

### 1. Clonar o Reposit√≥rio

Primeiro, clone este reposit√≥rio para a sua m√°quina local e navegue at√© a pasta do projeto.

```bash
# Clone o projeto
git clone https://github.com/marceloverass/cb-lab

# Entre na pasta do projeto
cd cb-lab
```

### 2. Iniciar os Cont√™ineres

Este comando ir√° construir as imagens Docker e iniciar os servi√ßos da aplica√ß√£o e do banco de dados em segundo plano (`-d`).

```bash
docker compose up --build -d
```

Ap√≥s a execu√ß√£o, verifique se os dois cont√™ineres (`desafio_app` e `desafio_db`) est√£o em execu√ß√£o e saud√°veis:

```bash
# Deve listar os dois cont√™ineres com o status "Up"
docker ps
```

### 3. Configurar o Banco de Dados

Os comandos a seguir preparam o banco de dados `DesafioDB` e criam as tabelas necess√°rias.

**3.1. Criar o Banco de Dados**
Este comando executa um script SQL dentro do cont√™iner do banco de dados para criar a base `DesafioDB`, caso ela n√£o exista.

```bash
docker exec -it desafio_db /opt/mssql-tools18/bin/sqlcmd -S localhost -U sa -P 'CocoBambuCBLAB123@@' -N -C -Q "IF NOT EXISTS (SELECT name FROM sys.databases WHERE name = 'DesafioDB') CREATE DATABASE DesafioDB;"
```

**3.2. Criar as Tabelas**
Agora, copiamos o arquivo `schema.sql` para dentro do cont√™iner e o executamos para criar a estrutura de tabelas.

```bash
# 1. Copia o arquivo de schema para o cont√™iner
docker cp desafio1/sql/schema.sql desafio_db:/tmp/schema.sql
```

```bash
# 2. Executa o script para criar as tabelas dentro do banco DesafioDB
docker exec -it desafio_db /opt/mssql-tools18/bin/sqlcmd -S localhost -U sa -P 'CocoBambuCBLAB123@@' -N -C -d DesafioDB -i /tmp/schema.sql
```

### 4. Executar o Pipeline de Dados

Com o ambiente pronto, execute cada etapa do pipeline de dados. Os scripts Python ser√£o executados dentro do cont√™iner da aplica√ß√£o.

**4.1. Etapa 1: Ingest√£o da API para a Camada Bronze**

(Se quiser testar essa etapa do zero delete a pasta `data-lake`).

```bash
docker exec -it desafio_app python desafio2/src/ingestao_api.py
```

**4.2. Etapa 2: Transforma√ß√£o de Bronze para Silver**

```bash
docker exec -it desafio_app python desafio1/src/etl-prod/transform_silver.py
```

**4.3. Etapa 3: Carga de Silver para Gold (Data Warehouse)**

```bash
docker exec -it desafio_app python desafio1/src/etl-prod/main.py
```

Ao final desta etapa, o processo estar√° completo!

### 5. Verificando o Resultado

Ap√≥s a execu√ß√£o do pipeline, voc√™ pode verificar o resultado, testar consultas criadas como exemplo e criar suas pr√≥prias consultas:

**5.1. Acessar o Cont√™iner da Aplica√ß√£o**

Primeiro, acesse o terminal interativo (shell) do cont√™iner desafio_app. Todos os comandos seguintes ser√£o executados de dentro dele.

```bash
docker compose exec app bash
```

**5.2. Iniciar o Jupyter Notebook**

Execute o comando abaixo no seu terminal. Ele iniciar√° um servidor Jupyter dentro do cont√™iner da aplica√ß√£o e fornecer√° um link de acesso.

```bash
jupyter lab --notebook-dir=/app/docs/notebooks --ip=0.0.0.0 --port=8888 --allow-root --no-browser
```

**5.3. Acessar o Notebook**

O terminal exibir√° uma mensagem com um link. Segure `Ctrl` e clique no link que cont√©m `127.0.0.1:8888` ou cole-o no seu navegador. O link ser√° parecido com este:

```
http://127.0.0.1:8888/lab?token=6c5e1e729cf9c39dd12c7e1c51acc87237b1a87f41756131
```

**5.4. Executar o Notebook**

Na interface do Jupyter, navegue at√© a pasta `desafio1/notebooks/` e abra o arquivo `exploracao_datawarehouse.ipynb`. Siga as instru√ß√µes e execute as c√©lulas do notebook para ver a an√°lise dos dados.

### 6. Encerrar o Ambiente

Quando terminar a avalia√ß√£o, voc√™ pode parar e remover todos os cont√™ineres e redes criados pelo projeto com um √∫nico comando:

```bash
docker compose down
```

## Autor

**[Marcelo Antonino Veras Sampaio]**

* [marceloantonino.verass@gmail.com]
* [https://www.linkedin.com/in/marceloveras/]