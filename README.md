# Desafio de Engenharia de Dados

Este reposit√≥rio cont√©m a solu√ß√£o completa para os desafios de Engenharia de Dados propostos. O projeto implementa um pipeline de dados de ponta a ponta, desde a ingest√£o de dados de APIs at√© a sua disponibiliza√ß√£o em um Data Warehouse modelado para an√°lises de neg√≥cio.

## Arquitetura da Solu√ß√£o

A solu√ß√£o foi projetada utilizando a **Arquitetura Medallion**, um padr√£o moderno que organiza os dados em tr√™s camadas l√≥gicas de qualidade, garantindo robustez, rastreabilidade e flexibilidade ao fluxo de dados.

Todo o ambiente √© 100% containerizado com Docker para garantir a total reprodutibilidade.

## Tecnologias Utilizadas

* **Linguagem:** Python
* **Bibliotecas:** Pandas, PyArrow, PyODBC
* **Containeriza√ß√£o:** Docker & Docker Compose
* **Banco de Dados:** Microsoft SQL Server
* **Documenta√ß√£o:** Jupyter Notebook, Kanban

---

## üöÄ Como Executar o Projeto

### Pr√©-requisitos

* Docker e Docker Compose devem estar instalados e em execu√ß√£o.
* Git para clonar o reposit√≥rio.

### Passo 1: Clone o Reposit√≥rio

```bash
git clone [https://github.com/marceloverass/cb-lab]
cd [cb-lab]
```

### Passo 2: Inicie o Ambiente Docker

Este comando utiliza os arquivos de configura√ß√£o na pasta `docker/` para construir a imagem da aplica√ß√£o Python e iniciar os containers da aplica√ß√£o (`desafio_app`) e do banco de dados (`desafio_db`).

```bash
docker compose -f docker/docker-compose.yml up --build -d
```
**Importante:** Ap√≥s executar o comando, aguarde de **1 a 2 minutos** para que o servi√ßo do SQL Server seja totalmente inicializado antes de prosseguir.

### Passo 3: Execute o Pipeline de Dados Completo

Os comandos abaixo devem ser executados em sequ√™ncia. Eles ir√£o inicializar o banco de dados (se necess√°rio) e executar todo o fluxo de dados atrav√©s das camadas Bronze, Silver e Gold.

**3.1 - Setup do Banco de Dados (s√≥ precisa rodar uma vez):**
```bash
# Cria o Banco de Dados
docker exec -it desafio_db /opt/mssql-tools18/bin/sqlcmd -S localhost -U sa -P 'CocoBambuCBLAB123@@' -N -C -Q "IF NOT EXISTS (SELECT name FROM sys.databases WHERE name = 'DesafioDB') CREATE DATABASE DesafioDB;"

# Copia e executa o script para criar as tabelas
docker cp desafio1/sql/schema.sql desafio_db:/tmp/schema.sql
docker exec -it desafio_db /opt/mssql-tools18/bin/sqlcmd -S localhost -U sa -P 'CocoBambuCBLAB123@@' -N -C -d DesafioDB -i /tmp/schema.sql
```

**3.2 - Execu√ß√£o do Pipeline de Dados:**
```bash
# Etapa 1: Ingest√£o da API para a camada Bronze
docker exec -it desafio_app python desafio2/src/ingestao_api.py

# Etapa 2: Transforma√ß√£o de Bronze para Silver
docker exec -it desafio_app python desafio1/src/etl-prod/transform_silver.py

# Etapa 3: Carga de Silver para Gold (Data Warehouse)
docker exec -it desafio_app python desafio1/src/etl-prod/main.py
```

Ap√≥s a execu√ß√£o, o Data Warehouse estar√° populado e pronto para ser consultado.

---
## üìÑ Visualizando a Documenta√ß√£o e An√°lise

Todo o processo de design e modelagem foi documentado em Jupyter Notebooks.

**1. Inicie o servidor JupyterLab:**
```bash
# Entra no terminal do container da aplica√ß√£o
docker compose -f docker/docker-compose.yml exec app bash

# Dentro do container, executa o JupyterLab
jupyter lab --ip=0.0.0.0 --allow-root --port=8888 --no-browser --notebook-dir=/app/docs/notebooks
```

**2. Acesse no Navegador:**
Copie o link que aparecer√° no terminal (incluindo o `token`) e cole no seu navegador.

**3. Documenta√ß√£o Adicional:**
* **Gest√£o de Tarefas:** O progresso do projeto foi acompanhado atrav√©s do arquivo `docs/KANBAN.md`.
* **Diagramas de Modelo:** Os diagramas MER e DER est√£o localizados na pasta `docs/`.